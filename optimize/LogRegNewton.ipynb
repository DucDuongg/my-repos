{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "from datetime import datetime\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]] [7 8 9]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,2], [3,4], [5,6]])\n",
    "y = np.array([7,8,9])\n",
    "\n",
    "print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function, return cost and gradient value\n",
    "def cost(theta, X, y):\n",
    "    N = len(y)\n",
    "    \n",
    "    print(X.shape)\n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "\n",
    "    # cost\n",
    "    J = np.dot(y, np.log(h)) + np.dot( (1-y), np.log(1-h) )\n",
    "    J = -J/N\n",
    "    \n",
    "    # gradient\n",
    "    #dJ   = np.dot(X.T, (h - y)) / N\n",
    "    dJ   = (X.T @ (h - y)) / N\n",
    "    \n",
    "    # hessian\n",
    "    Hess = (X.T @ np.diag(h) @ np.diag(1-h) @ X) / N\n",
    "    \n",
    "    return J, dJ, Hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient function\n",
    "def grad(theta, X, y):\n",
    "    N = len(y)\n",
    "    \n",
    "    h = sigmoid(np.dot(X, theta))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return dJ, Hess\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 2]\n",
      " [1 3 4]\n",
      " [1 5 6]]\n",
      "Iter  0\n",
      "(3, 3)\n",
      "Hessian: [[0.25       0.75       1.        ]\n",
      " [0.75       2.91666667 3.66666667]\n",
      " [1.         3.66666667 4.66666667]]\n",
      "theta: [192. -32. -32.]\n",
      "Iter  1\n",
      "(3, 3)\n",
      "Hessian: [[4.22138852e-15 1.26641655e-14 1.68855541e-14]\n",
      " [1.26641655e-14 3.79924966e-14 5.06566622e-14]\n",
      " [1.68855541e-14 5.06566622e-14 6.75422163e-14]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmduc/installs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-0574cad96ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hessian:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"theta:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/installs/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m     \u001b[0mainv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/installs/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Singular matrix\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "#c,g,H = cost(np.array([0,0]), X, y)\n",
    "\n",
    "#print(H)\n",
    "\n",
    "#print(np.dot(inv(H), g))\n",
    "\n",
    "#print(inv(H) @ g)\n",
    "\n",
    "#theta = [0,0] - (inv(H) @ g)\n",
    "a = np.insert(X, 0, values=1, axis=1)\n",
    "print(a)\n",
    "\n",
    "theta = [0, 0, 0]\n",
    "for i in np.arange(2):\n",
    "    print(\"Iter \",i)\n",
    "    c,g,H = cost(theta, a, y)\n",
    "    print(\"Hessian:\", H)\n",
    "    theta = theta - (inv(H) @ g)\n",
    "    print(\"theta:\", theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training with Newton method\n",
    "def myGD_Newton(theta_init, grad, t, X, y,  iterations):\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    cost_array = []\n",
    "    theta_array = [theta_init]\n",
    "    \n",
    "    for it in range( iterations): # so buoc lap toi da\n",
    "        \n",
    "        # cost, gradient, hessian\n",
    "        c, g, H = cost(theta_array[-1], X, y)\n",
    "        \n",
    "        # check stop condition, if not satisfy, update theta\n",
    "        if (norm(g)/len(theta_array[-1])) < 1e-3:\n",
    "        #if (np.linalg.norm(gradient_current)) < 1e-3:\n",
    "            break\n",
    "        \n",
    "        #theta_new = theta_array[-1] - t*gradient_current\n",
    "        theta_new = theta_array[-1] - (inv(H) @ g)\n",
    "        \n",
    "        theta_array.append(theta_new)\n",
    "        cost_array.append(c)        \n",
    "        \n",
    "    print(f'Running time with Gradient Descent: {datetime.now() - start_time}')\n",
    "    return (theta_array, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lam viec voi du lieu data1\n",
    "df1 = pd.read_csv(\"voice.csv\").values\n",
    "print(df1.shape)\n",
    "X1=df1[:,0:20]\n",
    "y1=df1[:,20]\n",
    "N = df1.shape[0]\n",
    "print(N)\n",
    "\n",
    "X1 = np.array(X1, dtype=np.float64)\n",
    "mean = X1.mean(axis = 0)\n",
    "std = X1.std(axis = 0)\n",
    "X1 = (X1 - mean)/std\n",
    "X1 = np.hstack((np.ones((N, 1)), X1))\n",
    "D1 = X1.shape[1]\n",
    "print(D1)\n",
    "\n",
    "## Khoi tao cac gia tri\n",
    "theta_init = np.zeros(D1).T # khoi tao gia tri anpha\n",
    "t_init = 0.1\n",
    "beta = 0.5\n",
    "alpha = 0.5\n",
    "iterations =1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ chay thuat toan GD\n",
    "(theta, it) = myGD_Newton(theta_init, grad, t_init, X1, y1,  iterations) ## cho gia tri t=1 hoac 1/2 \n",
    "print('Thuat toan gradient descent:', theta[-1])\n",
    "print('So buoc lap: ',it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ chay thuat toan GD Newton method\n",
    "(theta, it) = myGD_Newton(theta_init, grad, t_init, X1, y1,  iterations) ## cho gia tri t=1 hoac 1/2 \n",
    "print('Thuat toan gradient descent:', theta[-1])\n",
    "print('So buoc lap: ',it)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
